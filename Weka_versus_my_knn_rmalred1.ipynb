{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rajnish379/Machine_Learning/blob/main/Weka_versus_my_knn_rmalred1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn import datasets\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = datasets.load_iris()\n",
        "iris_data = iris.data\n",
        "# iris_target contains the encoded integer which indicates the target class of the specific row i.e, 0 for setosa, 1 for versicolor and 2 for virginica.\n",
        "iris_target = iris.target"
      ],
      "metadata": {
        "id": "JOmTIaBv-SNv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We are ignoring the third column i.e., column with index 2 from the iris dataset\n",
        "X_train = iris_data[::2,[0, 1, 3]] # Slicing for elements with even indices starting from 0 with a step of 2\n",
        "X_test = iris_data[1::2,[0,1,3]] # Slicing for elements with odd indices starting from 1 with a step of 2\n",
        "# X is capital because X_train is a matrix which contains n number of of rows and m number of columns"
      ],
      "metadata": {
        "id": "X4o1PFGb6Dc6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# iris.target_names contains the decoded class name for the iris flower species (setosa for 0, versicolor for 1 and virginica for 2)\n",
        "# We need to decode the class names especially because we have to create arff files for weka. Weka uses actual class names instead of 0,1 and 2 which is why we have to do this\n",
        "y_train = iris.target_names[iris_target[::2]] # We are storing the decoded names from the target of iris dataset corresponding to even indices in y_train\n",
        "y_test = iris.target_names[iris_target[1::2]] # We are storing the decoded names from the target of iris dataset corresponding to odd indices in y_test\n",
        "# Here y is small in y_train because it usually indicates that each row of it has only one element"
      ],
      "metadata": {
        "id": "PasHb5s-95Lh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_names = iris.feature_names[:]\n",
        "print(feature_names)\n",
        "del feature_names[2] # We don't need the third feature header so deleting it\n",
        "feature_names = [x.replace(' ','') for x in feature_names]\n",
        "print(feature_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BQC5okkjgU8l",
        "outputId": "9e81ac1e-d2de-4da5-bb2b-ac0ab5bc3846"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
            "['sepallength(cm)', 'sepalwidth(cm)', 'petalwidth(cm)']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# In concatenate, axis = 1 means horizontal concatenation and 0 is for vertical\n",
        "column_names = feature_names + ['Class-labels']\n",
        "Xy_train = np.hstack((X_train, y_train.reshape(-1,1))) # Here y_train and y_test are reshaped such that it has only one column instead of one row as before\n",
        "Xy_test = np.hstack((X_test,y_test.reshape(-1,1)))\n",
        "train_matrix = np.vstack((column_names, Xy_train))\n",
        "test_matrix = np.vstack((column_names,Xy_test))"
      ],
      "metadata": {
        "id": "vVNOoS2wip0B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.savetxt('training_set.csv', train_matrix, '%s', delimiter=',')\n",
        "np.savetxt('test_set.csv',test_matrix,'%s',delimiter = ',')"
      ],
      "metadata": {
        "id": "VVIHT5ULf3pO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to calculate the distance between each row of two datasets\n",
        "def calculate_distances(train_data, test_data):\n",
        "    distances = np.zeros((test_data.shape[0], train_data.shape[0]))\n",
        "\n",
        "    for i, test_row in enumerate(test_data):\n",
        "        for j, train_row in enumerate(train_data):\n",
        "            # Euclidean distance\n",
        "#            distances[i, j] = np.linalg.norm(test_row - train_row)\n",
        "            distances[i, j] = np.sqrt(np.sum((test_row - train_row)**2))\n",
        "\n",
        "    return distances"
      ],
      "metadata": {
        "id": "ocVRzgCLWtfT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_test = len(X_test)\n",
        "\n",
        "nearest_neighbors_indices = np.zeros(n_test, dtype=int)\n",
        "\n",
        "for i in range(n_test):\n",
        "    # Calculate distances from the i-th sample to all samples in the training set\n",
        "    distances = calculate_distances(X_train, X_test[i].reshape(1, -1)).flatten() #should return 1-by-75 distances\n",
        "    distances[i] = np.inf\n",
        "\n",
        "    nearest_neighbors_indices[i] = np.argmin(distances)\n",
        "nearest_neighbors_indices"
      ],
      "metadata": {
        "id": "ilON9pj0WUcw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26c21284-7d22-4c1f-b1ee-66191df96635"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([17, 15,  8,  0, 17, 12, 19,  8, 20, 23, 22, 13, 17, 14,  1, 10,  7,\n",
              "       15,  2,  0,  4, 13, 15,  1, 17, 28, 40, 48, 49, 45, 39, 39, 43, 41,\n",
              "       40, 67, 67, 29, 43, 46, 45, 39, 35, 34, 45, 39, 49, 48, 37, 48, 71,\n",
              "       63, 61, 65, 60, 64, 71, 52, 60, 34, 71, 63, 51, 69, 26, 61, 27, 61,\n",
              "       58, 56, 60, 60, 70, 58, 69])"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds = y_train[nearest_neighbors_indices]"
      ],
      "metadata": {
        "id": "pLkt_bvEPSXe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sum(preds == y_test)"
      ],
      "metadata": {
        "id": "BkoRx9ZJb7aC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "375d861f-ac4b-4d1f-9c98-da2fa62de188"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "70"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(preds == y_test).mean()"
      ],
      "metadata": {
        "id": "quJIf6_RccPw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "643ef960-7a43-4d23-8164-934a2a371c04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9333333333333333"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.where(preds != y_test)"
      ],
      "metadata": {
        "id": "tZrUdB79ciFJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50987ad3-b951-4240-b4bb-3b504019598e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([35, 36, 59, 64, 66]),)"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "(array([35, 36, 59, 64, 66]),) These data points present in the training set are misclassified. The training set consists of 75 rows which are labeled starting from 0 to 74."
      ],
      "metadata": {
        "id": "j0yLAoNAuSMN"
      }
    }
  ]
}